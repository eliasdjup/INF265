{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split\n",
    "from torch import linalg as LA\n",
    "from datetime import datetime\n",
    "\n",
    "torch.manual_seed(123)\n",
    "torch.set_default_dtype(torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "else torch.device('cpu'))\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =  64\n",
    "n_epoch =  30\n",
    "loss_fn =  nn.CrossEntropyLoss()\n",
    "seed =  265"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1\n",
    "Load and preprocess the CIFAR-10 dataset. Split it into 3 datasets: training, validation and\n",
    "test. Take a subset of these datasets by keeping only 2 labels: bird and plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Size of the train dataset:         45000\n",
      "Size of the validation dataset:    5000\n",
      "Size of the test dataset:          10000\n",
      "Size of the training dataset:  9017\n",
      "Size of the validation dataset:  983\n",
      "Size of the test dataset:  2000\n"
     ]
    }
   ],
   "source": [
    "def load_cifar(train_val_split=0.9, data_path='../data/', preprocessor=None):\n",
    "    \n",
    "    # Define preprocessor if not already given\n",
    "    if preprocessor is None:\n",
    "        preprocessor = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                                (0.2470, 0.2435, 0.2616))\n",
    "        ])\n",
    "    \n",
    "    # load datasets\n",
    "    data_train_val = datasets.CIFAR10(\n",
    "        data_path,      \n",
    "        train=True,      \n",
    "        download=True,\n",
    "        transform=preprocessor)\n",
    "\n",
    "    data_test = datasets.CIFAR10(\n",
    "        data_path, \n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=preprocessor)\n",
    "\n",
    "    # train/validation split\n",
    "    n_train = int(len(data_train_val)*train_val_split)\n",
    "    n_val =  len(data_train_val) - n_train\n",
    "\n",
    "    data_train, data_val = random_split(\n",
    "        data_train_val, \n",
    "        [n_train, n_val],\n",
    "        generator=torch.Generator().manual_seed(123)\n",
    "    )\n",
    "\n",
    "    print(\"Size of the train dataset:        \", len(data_train))\n",
    "    print(\"Size of the validation dataset:   \", len(data_val))\n",
    "    print(\"Size of the test dataset:         \", len(data_test))\n",
    "    \n",
    "    return (data_train, data_val, data_test)\n",
    "\n",
    "cifar10_train, cifar10_val, cifar10_test = load_cifar()\n",
    "\n",
    "# Now define a lighter version of CIFAR10: cifar\n",
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "\n",
    "# For each dataset, keep only airplanes and birds\n",
    "cifar2_train = [(img, label_map[label]) for img, label in cifar10_train if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label]) for img, label in cifar10_val if label in [0, 2]]\n",
    "cifar2_test = [(img, label_map[label]) for img, label in cifar10_test if label in [0, 2]]\n",
    "\n",
    "print('Size of the training dataset: ', len(cifar2_train))\n",
    "print('Size of the validation dataset: ', len(cifar2_val))\n",
    "print('Size of the test dataset: ', len(cifar2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2\n",
    "Write a MyMLP class that implements a MLP in PyTorch (so only fully connected layers) such\n",
    "that:\n",
    "(a) The input dimension is 3072 (= 32*32*3) and the output dimension is 2 (for the 2\n",
    "classes).\n",
    "(b) The hidden layers have respectively 512, 128 and 32 hidden units.\n",
    "(c) All activation functions are ReLU. The last layer has no activation function since the\n",
    "cross-entropy loss already includes a softmax activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()  \n",
    "\n",
    "        self.flat = nn.Flatten()\n",
    "        # 32*32*3: determined by our dataset: 32x32 RGB images\n",
    "        self.fc1 = nn.Linear(32*32*3, 512)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(128, 32)\n",
    "        self.act3 = nn.ReLU()\n",
    "        # 2: determined by our number of classes (birds and planes)\n",
    "        self.fc4 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.flat(x)\n",
    "        out = self.act1(self.fc1(out))\n",
    "        out = self.act2(self.fc2(out))\n",
    "        out = self.act3(self.fc3(out))\n",
    "        out = self.fc4(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3\n",
    "Write a train(n epochs, optimizer, model, loss fn, train loader) function that trains model for n epochs epochs given an optimizer optimizer, a loss function loss fn and a dataloader train loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    n_batch = len(train_loader)\n",
    "    losses_train = []\n",
    "    model.train()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        \n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "\n",
    "            imgs = imgs.to(device=device, dtype=torch.double)\n",
    "            labels = labels.to(device=device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "            \n",
    "        losses_train.append(loss_train / n_batch)\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{}  |  Epoch {}  |  Training loss {:.3f}'.format(\n",
    "                datetime.now().time(), epoch, loss_train / n_batch))\n",
    "    return losses_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4\n",
    "Write a similar function train manual update that has no optimizer parameter, but a learning rate lr parameter instead and that manually updates each trainable parameter of model\n",
    "using equation (3). Do not forget to zero out all gradients after each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_manual_update(n_epochs, lr, model, loss_fn, train_loader, verbose = False):\n",
    "    n_batch = len(train_loader)\n",
    "    losses_train = []\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "\n",
    "            imgs = imgs.to(device=device, dtype=torch.double)\n",
    "            labels = labels.to(device=device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            # optimizer step\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= lr * p.grad\n",
    "            \n",
    "            # zero out all gradients\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p.grad.zero_()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "            \n",
    "        losses_train.append(loss_train / n_batch)\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0 or verbose:\n",
    "            print('{}  |  Epoch {}  |  Training loss {:.3f}'.format(\n",
    "                datetime.now().time(), epoch, loss_train / n_batch))\n",
    "    return losses_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5\n",
    "Train 2 instances of MyMLP, one using train and the other using train manual update (use\n",
    "the same parameter values for both models). Compare their respective training losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:03:03.904185  |  Epoch 1  |  Training loss 0.635\n",
      "13:03:13.876134  |  Epoch 10  |  Training loss 0.317\n",
      "13:03:24.915506  |  Epoch 20  |  Training loss 0.195\n",
      "13:03:36.010210  |  Epoch 30  |  Training loss 0.131\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed)\n",
    "model = MyMLP().to(device=device) \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "train_loader = torch.utils.data.DataLoader(cifar2_train, batch_size=batch_size, shuffle=False)\n",
    "res = train(n_epoch, optimizer, model, loss_fn, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:03:37.468136  |  Epoch 1  |  Training loss 0.635\n",
      "13:03:48.224021  |  Epoch 10  |  Training loss 0.317\n",
      "13:03:59.492313  |  Epoch 20  |  Training loss 0.195\n",
      "13:04:10.656989  |  Epoch 30  |  Training loss 0.131\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed)\n",
    "model = MyMLP().to(device=device) \n",
    "train_loader = torch.utils.data.DataLoader(cifar2_train, batch_size=batch_size, shuffle=False)\n",
    "lr = 0.01\n",
    "res = train_manual_update(n_epoch, lr, model, loss_fn, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the train and train_manual_update function produces the same training losses when given the same data and learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6\n",
    "\n",
    "Modify train manual update by adding a L2 regularization term in your manual parameter\n",
    "update. Add an additional weight decay parameter to train manual update. Compare\n",
    "again train and train manual update results with 0 < weight decay < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_manual_update(n_epochs, lr, weight_decay, model, loss_fn, train_loader):\n",
    "    n_batch = len(train_loader)\n",
    "    losses_train = []\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "\n",
    "            imgs = imgs.to(device=device, dtype=torch.double)\n",
    "            labels = labels.to(device=device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            # L2 regularization\n",
    "            if weight_decay != 0:\n",
    "                for parameter in model.parameters():\n",
    "                    if parameter.grad is None:\n",
    "                        continue\n",
    "                    else:\n",
    "                        grad = parameter.grad.data\n",
    "\n",
    "                        # Adding p.data (weight) multiplied by weight_decay since in the backward pass the gradient of w**2 is 2*w\n",
    "                        grad.add_(weight_decay, parameter.data)\n",
    "\n",
    "                        # Updates the weights with the gradient with the standard SGD formula.\n",
    "                        parameter.data.add_(-lr, grad)\n",
    "            \n",
    "            loss.backward()\n",
    "                \n",
    "            # optimizer step\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= lr * p.grad\n",
    "            \n",
    "            # zero out all gradients\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p.grad.zero_()\n",
    "        \n",
    "            loss_train += loss.item()\n",
    "            \n",
    "        losses_train.append(loss_train / n_batch)\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{}  |  Epoch {}  |  Training loss {:.3f}'.format(\n",
    "                datetime.now().time(), epoch, loss_train / n_batch))\n",
    "    return losses_train\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:04:11.903401  |  Epoch 1  |  Training loss 0.636\n",
      "13:04:22.025526  |  Epoch 10  |  Training loss 0.334\n",
      "13:04:33.572157  |  Epoch 20  |  Training loss 0.217\n",
      "13:04:44.922731  |  Epoch 30  |  Training loss 0.143\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed)\n",
    "model = MyMLP().to(device=device) \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=0.01)\n",
    "train_loader = torch.utils.data.DataLoader(cifar2_train, batch_size=batch_size, shuffle=False)\n",
    "res = train(n_epoch, optimizer, model, loss_fn, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3678/2202703499.py:26: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /tmp/pip-req-build-kchz20tw/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  grad.add_(weight_decay, parameter.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:04:46.214283  |  Epoch 1  |  Training loss 0.638\n",
      "13:04:57.060284  |  Epoch 10  |  Training loss 0.349\n",
      "13:05:08.924803  |  Epoch 20  |  Training loss 0.246\n",
      "13:05:20.997607  |  Epoch 30  |  Training loss 0.192\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed)\n",
    "model = MyMLP().to(device=device) \n",
    "train_loader = torch.utils.data.DataLoader(cifar2_train, batch_size=batch_size, shuffle=False)\n",
    "lr = 0.01\n",
    "weight_decay= 0.01\n",
    "res = train_manual_update(n_epoch, lr, weight_decay, model, loss_fn, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the results differ some with the manual implementation of L2 reguralization. We suspect this is from our L2 loss formula which i have struggled a bit with. We initially thought from Andrews videos was that we could implement with `L2_reg += torch.pow(param, 2).sum()` or `L2_reg += param.norm(2)`, but with this implementation we got drasticly different results from the pytorch implementation. We saw that often the formula is expressed as `/2 * w **2` so we tried with the implementation `0.5 * torch.pow(param, 2).sum()` which gave us more similar results. The current implementation works a bit simpler by using the fact that parameters have to be loaded and iterated over later during corrections performed by the optimizer. With this is mind we dont need to do power of 2 because the gradient of w**2 is 2*w\n",
    "We modify the existing gradient by adding p.data (weight) multiplied by weight_decay which results in an implementation done in-place. The last line updates the weights with the gradient with the standard SGD formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.7\n",
    "\n",
    "Modify train manual update by adding a momentum term in your parameter update. Add\n",
    "an additional momentum parameter to train manual update. Check again the correctness of\n",
    "the new update rule by comparing it to train function (with 0 < momentum < 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_manual_update(n_epochs, lr, weight_decay, momentum, model, loss_fn, train_loader):\n",
    "    n_batch = len(train_loader)\n",
    "    losses_train = []\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "\n",
    "        layers = sum([1 for _ in model.parameters()])\n",
    "        velocity = [[]] * layers\n",
    "\n",
    "        for imgs, labels in train_loader:\n",
    "\n",
    "            imgs = imgs.to(device=device, dtype=torch.double)\n",
    "            labels = labels.to(device=device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            \n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # L2 regularization\n",
    "            if weight_decay != 0:\n",
    "                for parameter in model.parameters():\n",
    "                    if parameter.grad is None:\n",
    "                        continue\n",
    "                    else:\n",
    "                        grad = parameter.grad.data\n",
    "\n",
    "                        # Adding p.data (weight) multiplied by weight_decay since in the backward pass the gradient of w**2 is 2*w\n",
    "                        grad.add_(weight_decay, parameter.data)\n",
    "\n",
    "                        # Updates the weights with the gradient with the standard SGD formula.\n",
    "                        parameter.data.add_(-lr, grad)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            # Momentum \n",
    "            if momentum != 0:\n",
    "                with torch.no_grad():\n",
    "                    for param_idx, param in enumerate(model.parameters()):\n",
    "                        if velocity[param_idx] == []:\n",
    "                            velocity[param_idx] = torch.zeros(param.grad.shape).to(device=device)\n",
    "\n",
    "                        velocity[param_idx] = velocity[param_idx] * momentum + param.grad\n",
    "                        \n",
    "                        param -= lr*velocity[param_idx]\n",
    "                    model.zero_grad()\n",
    "            \n",
    "            # Optimizer step\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= lr * p.grad\n",
    "            \n",
    "            # zero out all gradients\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p.grad.zero_()\n",
    "            \n",
    "            loss_train += loss.item()\n",
    "            \n",
    "        losses_train.append(loss_train / n_batch)\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{}  |  Epoch {}  |  Training loss {:.3f}'.format(\n",
    "                datetime.now().time(), epoch, loss_train / n_batch))\n",
    "    return losses_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:05:22.312178  |  Epoch 1  |  Training loss 0.505\n",
      "13:05:32.557347  |  Epoch 10  |  Training loss 0.191\n",
      "13:05:44.171285  |  Epoch 20  |  Training loss 0.114\n",
      "13:05:55.883847  |  Epoch 30  |  Training loss 0.057\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed)\n",
    "model = MyMLP().to(device=device) \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=0, momentum=0.9)\n",
    "train_loader = torch.utils.data.DataLoader(cifar2_train, batch_size=batch_size, shuffle=False)\n",
    "res = train(n_epoch, optimizer, model, loss_fn, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:05:57.273626  |  Epoch 1  |  Training loss 0.505\n",
      "13:06:08.862003  |  Epoch 10  |  Training loss 0.195\n",
      "13:06:21.808895  |  Epoch 20  |  Training loss 0.095\n",
      "13:06:34.839580  |  Epoch 30  |  Training loss 0.056\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed)\n",
    "model = MyMLP().to(device=device) \n",
    "train_loader = torch.utils.data.DataLoader(cifar2_train, batch_size=batch_size, shuffle=False)\n",
    "lr=0.01\n",
    "weight_decay=0\n",
    "momentum=0.9\n",
    "res = train_manual_update(n_epoch, lr, weight_decay, momentum, model, loss_fn, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implemented momentum by the defnition given in [Andrew's videos](https://www.youtube.com/watch?v=k8fTYJPd3_I). We initialize tensor of velocities which are computed for every gradient using the momentum input. With our manual momentum implementation we see that the two implementations converge in the same matter, but have slightly different numbers. We cannot quite pinpoint what makes these small differences, since to our understanding the momentum algorithm is implemented with the same logic as pytorch's implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.8\n",
    "\n",
    "Train different instances (at least 4) of the MyMLP model with different learning rate, momentum\n",
    "and weight decay values . You can choose the same values as in the\n",
    "gradient descent output.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =  256\n",
    "n_epoch =  30\n",
    "loss_fn =  nn.CrossEntropyLoss()\n",
    "seed =  265\n",
    "train_loader = torch.utils.data.DataLoader(cifar2_train, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:32:03.234594  |  Epoch 1  |  Training loss 0.681\n",
      "13:32:11.056466  |  Epoch 10  |  Training loss 0.465\n",
      "13:32:19.983478  |  Epoch 20  |  Training loss 0.384\n",
      "13:32:29.120044  |  Epoch 30  |  Training loss 0.318\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed)\n",
    "model1 = MyMLP().to(device=device) \n",
    "lr=0.01\n",
    "weight_decay=0\n",
    "momentum=0\n",
    "res = train_manual_update(n_epoch, lr, weight_decay, momentum, model1, loss_fn, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:32:30.149938  |  Epoch 1  |  Training loss 0.681\n",
      "13:32:38.541689  |  Epoch 10  |  Training loss 0.475\n",
      "13:32:47.832251  |  Epoch 20  |  Training loss 0.404\n",
      "13:32:57.022197  |  Epoch 30  |  Training loss 0.352\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed)\n",
    "model2 = MyMLP().to(device=device) \n",
    "lr=0.01\n",
    "weight_decay=0.01\n",
    "momentum=0\n",
    "res = train_manual_update(n_epoch, lr, weight_decay, momentum, model2, loss_fn, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:32:58.046741  |  Epoch 1  |  Training loss 0.618\n",
      "13:33:06.440061  |  Epoch 10  |  Training loss 0.266\n",
      "13:33:15.812640  |  Epoch 20  |  Training loss 0.215\n",
      "13:33:25.042414  |  Epoch 30  |  Training loss 0.100\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed)\n",
    "model3 = MyMLP().to(device=device) \n",
    "lr=0.01\n",
    "weight_decay=0\n",
    "momentum=0.9\n",
    "res = train_manual_update(n_epoch, lr, weight_decay, momentum, model3, loss_fn, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:33:26.114930  |  Epoch 1  |  Training loss 0.618\n",
      "13:33:34.709452  |  Epoch 10  |  Training loss 0.268\n",
      "13:33:44.216785  |  Epoch 20  |  Training loss 0.194\n",
      "13:33:53.849680  |  Epoch 30  |  Training loss 0.115\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed)\n",
    "model4 = MyMLP().to(device=device) \n",
    "lr=0.01\n",
    "weight_decay=0.001\n",
    "momentum=0.9\n",
    "res = train_manual_update(n_epoch, lr, weight_decay, momentum, model4, loss_fn, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:33:55.102387  |  Epoch 1  |  Training loss 0.598\n",
      "13:34:03.639401  |  Epoch 10  |  Training loss 0.269\n",
      "13:34:13.202753  |  Epoch 20  |  Training loss 0.240\n",
      "13:34:22.817917  |  Epoch 30  |  Training loss 0.233\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed)\n",
    "model5 = MyMLP().to(device=device) \n",
    "lr=0.02\n",
    "weight_decay=0.01\n",
    "momentum=0.8\n",
    "res = train_manual_update(n_epoch, lr, weight_decay, momentum, model5, loss_fn, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model1, model2, model3, model4, model5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.9\n",
    "Select the best model among those trained in the previous question based on their accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, train_loader, val_loader):\n",
    "    \"\"\"\n",
    "    Plot training and validation accuracy\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    accdict = {}\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device=device, dtype=torch.double)\n",
    "                labels = labels.to(device=device)\n",
    "\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1)\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "        accdict[name] = correct / total\n",
    "    return accdict\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Model  1 -----------\n",
      "Accuracy train: 0.88\n",
      "Accuracy val: 0.83\n",
      "-----------Model  2 -----------\n",
      "Accuracy train: 0.86\n",
      "Accuracy val: 0.83\n",
      "-----------Model  3 -----------\n",
      "Accuracy train: 0.90\n",
      "Accuracy val: 0.81\n",
      "-----------Model  4 -----------\n",
      "Accuracy train: 0.96\n",
      "Accuracy val: 0.84\n",
      "-----------Model  5 -----------\n",
      "Accuracy train: 0.88\n",
      "Accuracy val: 0.81\n"
     ]
    }
   ],
   "source": [
    "for i, m in enumerate(models):\n",
    "    print(\"-----------Model \",i+1,\"-----------\")\n",
    "    validate(m, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.10\n",
    "We choose model 4 since it gives us the highest validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of model 4: 0.85\n"
     ]
    }
   ],
   "source": [
    "test_loader =  torch.utils.data.DataLoader(cifar2_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs = imgs.to(device=device, dtype=torch.double)\n",
    "        labels = labels.to(device=device)\n",
    "\n",
    "        outputs = model4(imgs)\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "\n",
    "print(\"Test accuracy of model 4: {:.2f}\".format(correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a test accuracy (85%) which is almost the same as for validation (84%) which is what we expected"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f2237f2d220ad310471ebc7a3ba2d52d32f1f45a06155c1490d637beab9bd187"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('INF265_gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
